{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flow_tools.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqzKwA9s88EXiw+dW6fh7P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sxela/flow_tools/blob/main/flow_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make file"
      ],
      "metadata": {
        "id": "Yqxax6IWme5Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "VGz0SF1Ibvi6"
      },
      "outputs": [],
      "source": [
        "#@title Create start.py\n",
        "%%writefile check_consistency.py\n",
        "\n",
        "import argparse\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import torch\n",
        "from torch.nn.functional import grid_sample\n",
        "\n",
        "def sample(tensor, uv):\n",
        "      height, width = tensor.shape[-2:]\n",
        "      max_pos = torch.tensor([width - 1, height - 1], device=tensor.device).view(2, 1, 1)\n",
        "      grid = uv.div(max_pos / 2).sub(1).movedim(0, -1).unsqueeze(0)\n",
        "      return grid_sample(tensor.unsqueeze(0), grid, align_corners=True).squeeze(0)\n",
        "\n",
        "def make_consistency(flow1, flow2, edges_unreliable=False):\n",
        "      # Awesome pythonic consistency check from [maua](https://github.com/maua-maua-maua/maua/blob/44485c745c65cf9d83cb1b1c792a177588e9c9fc/maua/flow/consistency.py) by Hans Brouwer and Henry Rachootin\n",
        "      # algorithm based on https://github.com/manuelruder/artistic-videos/blob/master/consistencyChecker/consistencyChecker.cpp\n",
        "      # reimplemented in numpy by Hans Brouwer\n",
        "      # // consistencyChecker\n",
        "      # // Check consistency of forward flow via backward flow.\n",
        "      # // (c) Manuel Ruder, Alexey Dosovitskiy, Thomas Brox 2016\n",
        "\n",
        "      flow1 = np.flip(flow1, axis=2)\n",
        "      flow2 = np.flip(flow2, axis=2)\n",
        "      h, w, _ = flow1.shape\n",
        "\n",
        "      # get grid of coordinates for each pixel\n",
        "      orig_coord = np.flip(np.mgrid[:w, :h], 0).T\n",
        "\n",
        "      # find where the flow1 maps each pixel\n",
        "      warp_coord = orig_coord + flow1\n",
        "\n",
        "      # clip the coordinates in bounds and round down\n",
        "      warp_coord_inbound = np.zeros_like(warp_coord)\n",
        "      warp_coord_inbound[..., 0] = np.clip(warp_coord[..., 0], 0, h - 2)\n",
        "      warp_coord_inbound[..., 1] = np.clip(warp_coord[..., 1], 0, w - 2)\n",
        "      warp_coord_floor = np.floor(warp_coord_inbound).astype(np.int)\n",
        "\n",
        "      # for each pixel: bilinear interpolation of the corresponding flow2 values around the point mapped to by flow1\n",
        "      alpha = warp_coord_inbound - warp_coord_floor\n",
        "      flow2_00 = flow2[warp_coord_floor[..., 0], warp_coord_floor[..., 1]]\n",
        "      flow2_01 = flow2[warp_coord_floor[..., 0], warp_coord_floor[..., 1] + 1]\n",
        "      flow2_10 = flow2[warp_coord_floor[..., 0] + 1, warp_coord_floor[..., 1]]\n",
        "      flow2_11 = flow2[warp_coord_floor[..., 0] + 1, warp_coord_floor[..., 1] + 1]\n",
        "      flow2_0_blend = (1 - alpha[..., 1, None]) * flow2_00 + alpha[..., 1, None] * flow2_01\n",
        "      flow2_1_blend = (1 - alpha[..., 1, None]) * flow2_10 + alpha[..., 1, None] * flow2_11\n",
        "      warp_coord_flow2 = (1 - alpha[..., 0, None]) * flow2_0_blend + alpha[..., 0, None] * flow2_1_blend\n",
        "\n",
        "      # coordinates that flow2 remaps each flow1-mapped pixel to\n",
        "      rewarp_coord = warp_coord + warp_coord_flow2\n",
        "\n",
        "      # where the difference in position after flow1 and flow2 are applied is larger than a threshold there is likely an\n",
        "      # occlusion. set values to -1 so the final gaussian blur will spread the value a couple pixels around this area\n",
        "      squared_diff = np.sum((rewarp_coord - orig_coord) ** 2, axis=2)\n",
        "      threshold = 0.01 * np.sum(warp_coord_flow2 ** 2 + flow1 ** 2, axis=2) + 0.5\n",
        "      reliable_flow = np.where(squared_diff >= threshold, -0.75, 1)\n",
        "\n",
        "      # areas mapping outside of the frame are also occluded (don't need extra region around these though, so set 0)\n",
        "      if edges_unreliable:\n",
        "          reliable_flow = np.where(\n",
        "              np.logical_or.reduce(\n",
        "                  (\n",
        "                      warp_coord[..., 0] < 0,\n",
        "                      warp_coord[..., 1] < 0,\n",
        "                      warp_coord[..., 0] >= h - 1,\n",
        "                      warp_coord[..., 1] >= w - 1,\n",
        "                  )\n",
        "              ),\n",
        "              0,\n",
        "              reliable_flow,\n",
        "          )\n",
        "\n",
        "      # get derivative of flow, large changes in derivative => edge of moving object\n",
        "      dx = np.diff(flow1, axis=1, append=0)\n",
        "      dy = np.diff(flow1, axis=0, append=0)\n",
        "      motion_edge = np.sum(dx ** 2 + dy ** 2, axis=2)\n",
        "      motion_threshold = 0.01 * np.sum(flow1 ** 2, axis=2) + 0.002\n",
        "      reliable_flow = np.where(np.logical_and(motion_edge > motion_threshold, reliable_flow != -0.75), 0, reliable_flow)\n",
        "\n",
        "      return reliable_flow\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--flow_fwd\", type=str, help=\"Forward flow path\")\n",
        "parser.add_argument(\"--flow_bwd\", type=str, help=\"Backward flow path\")\n",
        "parser.add_argument(\"--output\", type=str, help=\"Output consistency map path\")\n",
        "parser.add_argument(\"--image_output\", action='store_true', help=\"Output consistency map as b\\w image path\")\n",
        "parser.add_argument(\"--blur\", type=float, default=2., help=\"Gaussian blur kernel size (0 for no blur)\")\n",
        "parser.add_argument(\"--bottom_clamp\", type=float, default=0., help=\"Clamp lower values\")\n",
        "parser.add_argument(\"--edges_reliable\", action='store_true', help=\"Consider edges reliable\")\n",
        "args = parser.parse_args()\n",
        "\n",
        "def run(args):\n",
        "  flow1 = np.load(args.flow_fwd)\n",
        "  flow2 = np.load(args.flow_bwd)\n",
        "  consistency_map = make_consistency(flow1, flow2, edges_unreliable=not args.edges_reliable)\n",
        "\n",
        "  # blur\n",
        "  if args.blur>0.:\n",
        "    consistency_map = scipy.ndimage.gaussian_filter(consistency_map, [3, 3])\n",
        "\n",
        "  #clip values between bottom_clamp and 1\n",
        "  bottom_clamp = min(max(args.bottom_clamp,0.), 0.999)\n",
        "  consistency_map = consistency_map.clip(bottom_clamp, 1)\n",
        "  np.save(args.output, consistency_map)\n",
        "\n",
        "  #save as jpeg \n",
        "  if args.image_output:\n",
        "    PIL.Image.fromarray((consistency_map*255.).astype('uint8')).save(args.output+'.jpg')\n",
        "\n",
        "\n",
        "run(args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check consistency"
      ],
      "metadata": {
        "id": "llLaXpw-mMDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/check_consistency.py --flow_fwd /content/0061.jpg.npy --flow_bwd /content/0061.jpg_12.npy --output /content/cc_map.np --image_output"
      ],
      "metadata": {
        "id": "uqO6Y3uUlax_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validate"
      ],
      "metadata": {
        "id": "scX9RmCWmOOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = np.load('/content/cc_map.np.npy'); \n",
        "display(PIL.Image.fromarray(((weights).clip(0., 1)*255).astype('uint8')))\n",
        "weights.shape, weights.min(), weights.max()"
      ],
      "metadata": {
        "id": "flheQfE_mQWR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}